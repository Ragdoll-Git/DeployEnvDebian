# ğŸ§  BrainBash âœ¨

![Python](https://img.shields.io/badge/Python-3.7%2B-blue?logo=python&logoColor=white)
![Platform](https://img.shields.io/badge/Platform-Debian%20|%20Alpine%20|%20Fedora-gray?logo=linux)

## ğŸ“‹ DescripciÃ³n

**BrainBash** es una aplicaciÃ³n modular escrita en **Python** que detecta automÃ¡ticamente tu distribuciÃ³n Linux y configura tu entorno en minutos y agrega integracion con IA local (sin internet) y en la nube (con internet).

**Soporte:**

- ğŸ¥ **Debian / Ubuntu / Kali** (apt)
- ğŸ”ï¸ **Alpine Linux** (apk)
- ğŸ© **Fedora / RHEL / CentOS** (dnf)

## ğŸš€ InstalaciÃ³n RÃ¡pida

Podes copiar el siguiente script de instalaciÃ³n en tu terminal:

```bash
bash <(curl -sL https://ragdoll-git.github.io/BrainBash/install.sh)
```

O clonarlo manualmente:

```bash
git clone https://github.com/Ragdoll-Git/BrainBash.git

cd BrainBash

python3 main.py
```

## ğŸ® Modo de Uso

AparecerÃ¡ un menÃº donde podrÃ¡s seleccionar:

- Actualizar el sistema.
- Instalar paquetes base y extra.
- Instalar entorno de desarrollo personalizado.
- Descargar tipos/modelos de IA local.
- Instalar y configurar Gemini 2.5 Flash.

*DespuÃ©s de terminada la instalacion, se puede acceder a cada modelo de IA local con el comando/alias:*

- `qwen: "pregunta"` o `qwen:`
- `gemma: "pregunta"` o `gemma:`
- `phi: "pregunta"` o `phi:`

### Modos de uso en la terminal

#### 1. Pregunta rapida

- `qwen: "pregunta"` - Hacer pregunta y recibir respuesta, ***sin contexto***
- `gemini: "pregunta"` - Hacer pregunta y recibir respuesta, ***sin contexto***

*Nota: no usar el signo **?** al final de la pregunta*

#### 2. Modo interactivo o chat

- `qwen:` - Inicia una sesion/chat con el modelo Qwen 3 0.6B. ***Usa contexto de la sesion.***
- `gemini:` - Inicia una sesion/chat con el modelo Gemini 2.5 Flash. ***Usa contexto de la sesion.***

*Nota: no usar el signo **?** al final de la pregunta*

## ğŸ“¦ Paquetes Incluidos

El sistema contiene los siguientes paquetes:

| Paquete | DescripciÃ³n |
| :--- | :--- |
| `zsh` | Shell alternativa mejorada |
| `git` | Control de versiones |
| `fzf` | BÃºsqueda difusa (Fuzzy Finder) |
| `bat` | Reemplazo de cat con sintaxis ( ejecutandose con cat o con alias batcat) |
| `eza` | Reemplazo moderno de ls |
| `htop` | Monitor de recursos interactivo |
| `tldr` | PÃ¡ginas de ayuda simplificadas (alternativa a man) |
| `zoxide` | NavegaciÃ³n de directorios inteligente (reemplazo de cd) |
| `curl` | Transferencia de datos |
| `python-dev` | Headers necesarios para compilar herramientas |

## ğŸ¤– IntegraciÃ³n IA

Una vez instalado, tu terminal tendrÃ¡ acceso a herramientas de IA (requiere Ollama instalado para los modelos locales):

Existen 4 tipos de modelos de IA disponibles:

- Qwen3:0.6B : Ligero **(523MB-40K tokens)**
- Gemma3:1B : Balanceado **(815MB-32K tokens)**
- Phi4-mini:latest : Pesado **(2.5GB-128K tokens)**
- Gemini 2.5 Flash (respaldo en la nube): requiere internet y una API Key de Google.
La puede conseguir gratis en <https://aistudio.google.com/>

## ğŸ§ª Testing con Docker

Puedes probar la interfaz en un entorno limpio usando Docker (Modo Interactivo):

```bash
# Prueba en Alpine
docker run -it --rm -v $(pwd):/app -w /app alpine:latest sh -c "apk add python3 sudo && python3 main.py"
```

## ğŸ¤ Contribuir

1. Haz un Fork.
2. Crea tu rama (`git checkout -b feature/nueva-distro`).
3. Haz tus cambios y aÃ±ade tests.
4. Push a la rama y abre un Pull Request.

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. VÃ©ase el archivo LICENSE para mÃ¡s detalles.

---
Hecho con ğŸ y â¤ï¸ por Ragdoll-Git.
